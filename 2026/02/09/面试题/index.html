<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>面试题 | Merick'Blog</title><meta name="author" content="Mercik"><meta name="copyright" content="Mercik"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大模型算法工程师高频面试题集锦 (2026版)  适用对象：拥有半年工作经验 + 硕士学历的算法工程师 核心考察点：基础深度（Transformer细节）、工程实践（SFT&#x2F;LoRA&#x2F;显存优化）、前沿理解（RLHF&#x2F;MoE&#x2F;Agent）   第一部分：Transformer 架构与基础（必考题） Q1: 为什么现在的 LLM（如 LLaMA）都用 Pre-RMSNorm 而不是 Post-Lay">
<meta property="og:type" content="article">
<meta property="og:title" content="面试题">
<meta property="og:url" content="https://duqi666.github.io/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="Merick&#39;Blog">
<meta property="og:description" content="大模型算法工程师高频面试题集锦 (2026版)  适用对象：拥有半年工作经验 + 硕士学历的算法工程师 核心考察点：基础深度（Transformer细节）、工程实践（SFT&#x2F;LoRA&#x2F;显存优化）、前沿理解（RLHF&#x2F;MoE&#x2F;Agent）   第一部分：Transformer 架构与基础（必考题） Q1: 为什么现在的 LLM（如 LLaMA）都用 Pre-RMSNorm 而不是 Post-Lay">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://duqi666.github.io/imgs/interview.png">
<meta property="article:published_time" content="2026-02-09T07:40:12.377Z">
<meta property="article:modified_time" content="2026-02-09T08:20:06.271Z">
<meta property="article:author" content="Mercik">
<meta property="article:tag" content="学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://duqi666.github.io/imgs/interview.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "面试题",
  "url": "https://duqi666.github.io/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/",
  "image": "https://duqi666.github.io/imgs/interview.png",
  "datePublished": "2026-02-09T07:40:12.377Z",
  "dateModified": "2026-02-09T08:20:06.271Z",
  "author": [
    {
      "@type": "Person",
      "name": "Mercik",
      "url": "https://duqi666.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://duqi666.github.io/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '面试题',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/universe.css"><link rel="stylesheet" href="/css/category.css"><link rel="stylesheet" href="/css/cat.css"><link rel="stylesheet" href="/css/neon_lamp.css"><link rel="stylesheet" href="/css/discuss.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/imgs/I.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 模式</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="javascript:void(0)"><i class="fa-fw fa-regular fa-moon"></i><span> dark</span></a></li><li><a class="site-page child" href="javascript:void(1)"><i class="fa-fw fa-regular fa-sun"></i><span> light</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/travel/"><i class="fa-fw fas fa-video"></i><span> 足迹</span></a></div><div class="menus_item"><a class="site-page" href="/charts/"><i class="fa-fw fas fa-video"></i><span> 图表</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/imgs/interview.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Merick'Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">面试题</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 模式</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="javascript:void(0)"><i class="fa-fw fa-regular fa-moon"></i><span> dark</span></a></li><li><a class="site-page child" href="javascript:void(1)"><i class="fa-fw fa-regular fa-sun"></i><span> light</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/travel/"><i class="fa-fw fas fa-video"></i><span> 足迹</span></a></div><div class="menus_item"><a class="site-page" href="/charts/"><i class="fa-fw fas fa-video"></i><span> 图表</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">面试题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2026-02-09T07:40:12.377Z" title="Created 2026-02-09 15:40:12">2026-02-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-09T08:20:06.271Z" title="Updated 2026-02-09 16:20:06">2026-02-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>5mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><meta name="referrer" content="no-referrer" />
<h1>大模型算法工程师高频面试题集锦 (2026版)</h1>
<blockquote>
<p><strong>适用对象</strong>：拥有半年工作经验 + 硕士学历的算法工程师<br>
<strong>核心考察点</strong>：基础深度（Transformer细节）、工程实践（SFT/LoRA/显存优化）、前沿理解（RLHF/MoE/Agent）</p>
</blockquote>
<hr>
<h2 id="第一部分：transformer-架构与基础-必考题">第一部分：Transformer 架构与基础（必考题）</h2>
<p><strong>Q1: 为什么现在的 LLM（如 LLaMA）都用 Pre-RMSNorm 而不是 Post-LayerNorm？</strong></p>
<ul>
<li><strong>核心考点</strong>：归一化位置对训练稳定性的影响。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>Post-LN（原版 Transformer）</strong>：放在残差连接之后。优点是理论上模型性能上限略高，但缺点是训练非常不稳定，梯度容易在深层消失或爆炸，很难训深层网络（需要 Warmup 极其小心）。</li>
<li><strong>Pre-LN</strong>：放在残差连接之前（子层输入前）。优点是训练非常稳定，梯度流可以直接通过残差路径传回底层，允许更深的网络和更大的学习率。</li>
<li><strong>RMSNorm</strong>：去掉了 LayerNorm 中的 Mean（平移）项，只保留 Variance（缩放）项。计算量更小，效果几乎持平。LLaMA 采用 Pre-RMSNorm 是为了<strong>极致的训练稳定性和速度</strong>。</li>
</ul>
</li>
</ul>
<p><strong>Q2: 详细解释一下 RoPE（旋转位置编码），它相比绝对位置编码有什么优势？</strong></p>
<ul>
<li><strong>核心考点</strong>：数学原理、外推性（Extrapolation）。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>绝对位置编码（Sinusoidal/Learnable）</strong>：直接加在 Embedding 上，模型很难学到 token 之间的相对距离（例如 token A 和 token B 距离为 5）。</li>
<li><strong>RoPE (Rotary Positional Embeddings)</strong>：通过将 Query 和 Key 向量在复数平面上旋转一个角度（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>θ</mi></mrow><annotation encoding="application/x-tex">m\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>），使得两个向量的点积（Attention Score）仅依赖于它们的相对距离 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>m</mi><mo>−</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(m-n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord mathit">m</span><span class="mbin">−</span><span class="mord mathit">n</span><span class="mclose">)</span></span></span></span>，而不是绝对位置。</li>
<li><strong>优势</strong>：具有良好的<strong>外推性</strong>（训练时由短序列推断长序列），且能够自然地结合绝对位置信息和相对位置信息。目前是 LLaMA 等主流模型的标配。</li>
</ul>
</li>
</ul>
<p><strong>Q3: MHA、MQA 和 GQA 的区别是什么？为什么 LLaMA 2/3 要用 GQA？</strong></p>
<ul>
<li><strong>核心考点</strong>：显存带宽、KV Cache 大小、推理速度。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>MHA (Multi-Head Attention)</strong>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.08125em;">H</span></span></span></span> 个 Query 对应 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.08125em;">H</span></span></span></span> 个 Key 和 Value。推理时 KV Cache 很大，显存占用高，吞吐量受限于显存带宽（Memory Bound）。</li>
<li><strong>MQA (Multi-Query Attention)</strong>：所有 Query 共享<strong>同一组</strong> Key 和 Value。KV Cache 极小，速度快，但模型表达能力下降较多。</li>
<li><strong>GQA (Grouped-Query Attention)</strong>：折中方案。将 Query 分组，每组共享一个 Key/Value。</li>
<li><strong>结论</strong>：LLaMA 2/3 使用 GQA 是为了在<strong>保持模型性能（接近 MHA）<strong>的同时，大幅</strong>降低推理时的 KV Cache 显存占用</strong>和<strong>提高推理吞吐量</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="第二部分：微调-sft-与参数高效微调-peft-实战题">第二部分：微调（SFT）与参数高效微调（PEFT）（实战题）</h2>
<p><strong>Q4: LoRA 的原理是什么？它的参数量怎么计算？为什么通常 rank 取 8 或 16 就够了？</strong></p>
<ul>
<li><strong>核心考点</strong>：低秩分解、矩阵运算。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>原理</strong>：冻结预训练权重 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">W_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，在旁路增加两个低秩矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">A</span></span></span></span>（降维）和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05017em;">B</span></span></span></span>（升维），即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi><mo>=</mo><mi>B</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">\Delta W = BA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Δ</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mord mathit">A</span></span></span></span>。前向传播时 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mi>x</mi><mo>+</mo><mi>B</mi><mi>A</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">h = W_0x + BAx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord mathit">h</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">x</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mord mathit">A</span><span class="mord mathit">x</span></span></span></span>。</li>
<li><strong>参数量</strong>：假设原矩阵是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{in} \times d_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">o</span><span class="mord mathit">u</span><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，秩为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span></span></span></span>。LoRA 参数量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>×</mo><mo>(</mo><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r \times (d_{in} + d_{out})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mbin">×</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">o</span><span class="mord mathit">u</span><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span>。通常 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>≪</mo><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r \ll d_{in}, d_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mrel">≪</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">o</span><span class="mord mathit">u</span><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。</li>
<li><strong>Rank 选择</strong>：实验表明大模型的权重更新矩阵具有“低秩性”（Intrinsic Dimension），即大部分参数更新是冗余的。Rank 8-64 通常能覆盖主要的变化方向。</li>
</ul>
</li>
</ul>
<p><strong>Q5: 在做 SFT 时，如果 Loss 突然出现 Spike（剧烈震荡）或者不下降，你会怎么排查？</strong></p>
<ul>
<li><strong>核心考点</strong>：训练 Trick、数据工程经验。</li>
<li><strong>参考回答（按优先级）</strong>：
<ol>
<li><strong>数据问题（最常见）</strong>：检查是否有脏数据（如乱码、HTML标签、极长文本），或者某些样本的 Label 为空。</li>
<li><strong>学习率（LR）</strong>：LR 是否过大？是否没有加 Warmup？通常 LLM 微调需要较小的 LR（如 2e-5）。</li>
<li><strong>梯度剪裁（Gradient Clipping）</strong>：是否设置了 <code>max_grad_norm</code>（如 1.0）来防止梯度爆炸？</li>
<li><strong>数值稳定性</strong>：是否使用了 fp16 而不是 bf16？fp16 容易溢出，bf16 范围更广，更稳。</li>
</ol>
</li>
</ul>
<hr>
<h2 id="第三部分：rlhf-与对齐-进阶题">第三部分：RLHF 与对齐（进阶题）</h2>
<p><strong>Q6: 为什么 RLHF 中需要一个 KL Divergence Penalty（KL 散度惩罚项）？</strong></p>
<ul>
<li><strong>核心考点</strong>：Reward Hacking、分布漂移。</li>
<li><strong>参考回答</strong>：
<ul>
<li>如果不加约束，模型为了最大化 Reward，会输出一些<strong>不仅不符合人类偏好，甚至是乱码</strong>的文本（这叫 Reward Hacking），只要 Reward Model 给分高就行。</li>
<li>KL Penalty 用于约束**当前训练策略（Policy）<strong>和</strong>初始参考模型（Reference Model）**之间的分布差异。</li>
<li><strong>目的</strong>：确保模型在学习人类偏好的同时，不要偏离原本的语言能力太远，防止“灾难性遗忘”或输出崩坏。</li>
</ul>
</li>
</ul>
<p><strong>Q7: DPO (Direct Preference Optimization) 相比 PPO 有什么优势？</strong></p>
<ul>
<li><strong>核心考点</strong>：算法演进、训练稳定性。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>PPO 痛点</strong>：训练流程极其复杂（需要 4 个模型：Actor, Critic, Ref, Reward），显存占用巨大，且超参数极其敏感，很难收敛。</li>
<li><strong>DPO 优势</strong>：推导出一个解析解，直接在**偏好数据对（Chosen/Rejected）**上通过类似 Binary Cross Entropy 的损失函数进行优化。</li>
<li><strong>核心</strong>：不需要显式的 Reward Model，也不需要在线采样（Sampling），将 RL 问题转化为了监督学习问题，训练更稳、更快、显存更低。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="第四部分：工程与推理优化-加分题">第四部分：工程与推理优化（加分题）</h2>
<p><strong>Q8: 什么是 KV Cache？随着序列长度增加，它会带来什么问题？如何解决？</strong></p>
<ul>
<li><strong>核心考点</strong>：自回归生成原理、显存瓶颈。</li>
<li><strong>参考回答</strong>：
<ul>
<li><strong>定义</strong>：在生成第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.61508em;"></span><span class="strut bottom" style="height:0.61508em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span></span></span></span> 个 token 时，前面 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span> 个 token 的 Key 和 Value 向量是固定的，不需要重新计算。将它们缓存下来叫 KV Cache。</li>
<li><strong>问题</strong>：显存占用线性增长（甚至 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>N</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>）。对于长文本（如 128k context），KV Cache 可能比模型参数本身还大，导致 Batch Size 只能开很小。</li>
<li><strong>解决方案</strong>：
<ol>
<li><strong>PagedAttention (vLLM)</strong>：像操作系统管理内存一样，非连续地存储 KV Cache，减少碎片化。</li>
<li><strong>GQA/MQA</strong>：减少 Key/Value 的头数。</li>
<li><strong>KV Quantization</strong>：将 KV Cache 量化为 fp8 或 int8。</li>
</ol>
</li>
</ul>
</li>
</ul>
<p><strong>Q9: 介绍一下 FlashAttention 的原理，为什么它能加速？</strong></p>
<ul>
<li><strong>核心考点</strong>：IO 瓶颈、GPU 架构。</li>
<li><strong>参考回答</strong>：
<ul>
<li>标准 Attention 的瓶颈不在计算（FLOPs），而在<strong>显存读写（HBM Access）</strong>。需要反复读写 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N \times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mbin">×</span><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span> 的 Attention Matrix。</li>
<li><strong>FlashAttention 核心</strong>：
<ol>
<li><strong>Tiling（分块）</strong>：将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">Q, K, V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">Q</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span> 切块，加载到 GPU 的片上高速缓存（SRAM）中进行计算。</li>
<li><strong>Recomputation（重计算）</strong>：在反向传播时不存储庞大的 Attention Matrix，而是重新计算它。</li>
</ol>
</li>
<li><strong>结果</strong>：虽然计算量（FLOPs）增加了，但大幅减少了 HBM 的读写次数（IO），从而实现了数倍的加速。</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://duqi666.github.io">Mercik</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://duqi666.github.io/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/">https://duqi666.github.io/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a></div><div class="post-share"><div class="social-share" data-image="/imgs/interview.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/02/09/GRPO/" title="GRPO算法"><img class="cover" src="/imgs/algorithm.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">GRPO算法</div></div><div class="info-2"><div class="info-item-1"> GRPO: Group Relative Policy Optimization 算法详解 本文档深入探讨 DeepSeek-R1 背后的关键强化学习算法——GRPO。我们将从传统的 PPO 算法痛点出发，详细解析 GRPO 的原理、数学推导、代码实现，并通过一个生动的大模型训练案例来演示其完整流程。  1. 背景回顾：PPO 的辉煌与痛点 在介绍 GRPO 之前，我们必须先回顾一下它的前辈——PPO (Proximal Policy Optimization)。PPO 是 ChatGPT 等大模型 RLHF 阶段的“版本答案”，但它并非完美。 1.1 PPO 的核心逻辑 (Actor-Critic) PPO 依赖于 Actor-Critic (AC) 架构：  Actor (策略网络 πθ\pi_\thetaπ​θ​​)：负责生成动作（Token）。 Critic (价值网络 VϕV_\phiV​ϕ​​)：负责给状态打分，充当“基线 (Baseline)”。  优势函数 (Advantage) 的计算依赖于 Critic： At=rt+γV(st+1)−V(st)A_t = ...</div></div></div></a><a class="pagination-related" href="/2026/02/09/%E7%AE%97%E6%B3%95/" title="一些算法"><img class="cover" src="/imgs/algorithm.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">一些算法</div></div><div class="info-2"><div class="info-item-1"> 排序算法 https://zhuanlan.zhihu.com/p/567134257 冒泡排序 它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果顺序（如从大到小、首字母从Z到A）错误就把他们交换过来。走访元素的工作是重复地进行，直到没有相邻元素需要交换，也就是说该元素列已经排序完成。   比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。   1234567def BubbleSort(mylist:list):    for z in range(len(mylist)):        #最后的z个已经排好序，不需要再排序了        for i in range(len(mylist) - z-1):            if mylist[i] &gt; mylist[i + 1]:                mylist[i],...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2026/02/09/CLIP/" title="多模态模型--CLIP"><img class="cover" src="/imgs/clip.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">多模态模型--CLIP</div></div><div class="info-2"><div class="info-item-1"> 打破次元壁：深入浅出 OpenAI CLIP 模型详解 在人工智能的发展历程中，计算机视觉（CV）和自然语言处理（NLP）长期以来是两个平行的领域。然而，OpenAI 在 2021 年发布的 CLIP (Contrastive Language-Image Pre-training) 模型，像一座桥梁一样，优雅而强力地连接了图像与文本。 CLIP 不仅在 Zero-shot（零样本）分类任务上表现惊人，更是后来大火的 Stable Diffusion 和 DALL-E 2 等文生图模型的基石。  1. 核心理念：从“教它认图”到“教它理解” 传统的图像分类模型（如 ResNet 在 ImageNet 上训练）是有监督学习。我们需要预先定义好 1000 个类别（猫、狗、飞机…），模型只能识别这 1000 类。如果你给它一张“皮卡丘”的图，它可能会强制将其分类为“黄鼠狼”或“气球”，因为它从未见过“皮卡丘”这个标签。 CLIP 摒弃了这种固定的分类头（Classification Head），转而使用自然语言作为监督信号。 CLIP 的核心思想是： 如果一个模型能学会判断** “哪...</div></div></div></a><a class="pagination-related" href="/2026/02/09/DPO/" title="DPO算法"><img class="cover" src="/imgs/algorithm.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">DPO算法</div></div><div class="info-2"><div class="info-item-1"> Direct Preference Optimization (DPO) 算法详解  目标：提供极其详细的原理介绍与公式推导，涵盖动机、理论基础、关键假设、目标函数推导、实现细节与局限性。全文强调数学严谨性与逻辑连贯性。   一、背景与动机：为什么需要 DPO？ 在大语言模型（LLM）对齐人类偏好过程中，人类反馈强化学习（RLHF） 是主流范式，典型流程为三阶段：  监督微调（SFT）：在高质量指令-回答对上微调预训练模型，得到初始策略 πSFT\pi_{\text{SFT}}π​SFT​​； 奖励建模（RM）：使用人类对模型生成回答的偏好数据（如 (x,yw,yl)(x, y_w, y_l)(x,y​w​​,y​l​​)，其中 ywy_wy​w​​ 是偏好的回答，yly_ly​l​​ 是不偏好的），训练一个奖励模型 rϕ(x,y)r_\phi(x, y)r​ϕ​​(x,y)； 强化学习优化（PPO）：以 rϕr_\phir​ϕ​​ 为奖励信号，用 PPO 等算法优化策略 πθ\pi_\thetaπ​θ​​，同时引入 KL 散度约束防止策略偏离 SFT 模型太远。  但 RLH...</div></div></div></a><a class="pagination-related" href="/2026/02/09/Diagrammatize_GPT/" title="《GPT图解》学习笔记"><img class="cover" src="/imgs/GPT2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">《GPT图解》学习笔记</div></div><div class="info-2"><div class="info-item-1"> Chapter1：N-grams &amp; Bag-of-words N-grams模型 N-grams是指将文本分割为连续的长度为N的文本片段，统计每个片段的频数以计算每个片段出现的条件概率，从而计算完整句子的出现概率。 该模型基于这样一种假设，第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram，下面具体解释其数学实现： 对于一个有mmm个词语的语句，其条件概率为： P(w1,w2,w3...wm)=P(w1)P(w2∣w1)P(w3∣w2,w1)...P(wm∣wm−1,wm−2...w1)P(w_1,w_2,w_3...w_m) = P(w_1)P(w_2|w_1)P(w_3|w_2,w_1)...P(w_m|w_{m-1},w_{m-2}...w_1) P(w​1​​,w​2​​,w​3​​...w​m​​)=P(w​1​​)P(w​2​​∣w​1​​)P(w​3​​∣w​2​​,w​1​​)...P(w​m​​...</div></div></div></a><a class="pagination-related" href="/2026/02/09/GRPO/" title="GRPO算法"><img class="cover" src="/imgs/algorithm.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">GRPO算法</div></div><div class="info-2"><div class="info-item-1"> GRPO: Group Relative Policy Optimization 算法详解 本文档深入探讨 DeepSeek-R1 背后的关键强化学习算法——GRPO。我们将从传统的 PPO 算法痛点出发，详细解析 GRPO 的原理、数学推导、代码实现，并通过一个生动的大模型训练案例来演示其完整流程。  1. 背景回顾：PPO 的辉煌与痛点 在介绍 GRPO 之前，我们必须先回顾一下它的前辈——PPO (Proximal Policy Optimization)。PPO 是 ChatGPT 等大模型 RLHF 阶段的“版本答案”，但它并非完美。 1.1 PPO 的核心逻辑 (Actor-Critic) PPO 依赖于 Actor-Critic (AC) 架构：  Actor (策略网络 πθ\pi_\thetaπ​θ​​)：负责生成动作（Token）。 Critic (价值网络 VϕV_\phiV​ϕ​​)：负责给状态打分，充当“基线 (Baseline)”。  优势函数 (Advantage) 的计算依赖于 Critic： At=rt+γV(st+1)−V(st)A_t = ...</div></div></div></a><a class="pagination-related" href="/2026/02/09/Flash-Attention/" title="Flash-Attention算法"><img class="cover" src="/imgs/Flash-Attention.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">Flash-Attention算法</div></div><div class="info-2"><div class="info-item-1"> 前言 学Flash-Attention算法的主要契机是最近在工作中遇到了进行长文本训练时的OOM（Out of Memory）问题，在训练时使用Flash-Attention是尝试过的有效的方法之一，所以就想学一下这个算法的原理。 Paper: https://arxiv.org/pdf/2205.14135 参考：https://www.zhihu.com/question/611236756/answer/3132304304 背景 传统的transformer算法中，对于self-attention的计算是一个比较费时费空间的做法，其存储复杂度是输入文本长度的平方复杂度，所以当输入序列变得很长时训练速度会变得比较慢，且存在OOM的风险，当前许多研究工作着重于减小self-attention的计算复杂度以加快训练速度，减小显存占用。 FlashAttention主要解决Transformer计算速度慢和存储占用高的问题。但与绝大多数Efficient Transformer把改进方法集中在降低模型的FLOPS（floating point operations per se...</div></div></div></a><a class="pagination-related" href="/2026/02/09/MOE/" title="MOE模型"><img class="cover" src="/imgs/MOE.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-09</div><div class="info-item-2">MOE模型</div></div><div class="info-2"><div class="info-item-1"> Why MOE模型？ 在一般的稠密（Dense）模型中，每次前向 / 反向需激活全部参数，导致计算与显存开销随参数量近乎线性增长，训练与推理成本急剧攀升，难以持续扩展。 在这样的背景下，研究者思考是否可以运用一种方法能让每次前向或反向计算时只激活部分参数，而不是激活所有参数，且模型效果不下降？ 一、MOE核心思想 混合专家模型（Mixture of Experts, MOE）的核心通过门控网络为输入token动态选择少数“专家网络”进行计算，而非激活所有参数，从而实现“高参数量（表达能力）”与“低计算量（效率）”的平衡。 可以参照医院，专科医生在学习时也只需要学校相应的专科知识（训练），每个病人去看病都会去找对应的专科医生（推理）。 二、基础架构与数学定义 MOE的基础架构包含3个核心组件：专家网络、门控网络、结果聚合。 1. 专家网络（Experts） 专家网络一般就是MLP网络，其输入长度为每个专家专精于输入空间的一个子集。  设共有 EEE 个专家，第 eee 个专家的函数为：  fe(x)=Experte(x)(e=1,2,...,E)f_e(\mathbf{x}) =...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/imgs/I.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Mercik</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">5</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Duqi666"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">大模型算法工程师高频面试题集锦 (2026版)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9Atransformer-%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%9F%BA%E7%A1%80-%E5%BF%85%E8%80%83%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">第一部分：Transformer 架构与基础（必考题）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E5%BE%AE%E8%B0%83-sft-%E4%B8%8E%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83-peft-%E5%AE%9E%E6%88%98%E9%A2%98"><span class="toc-number">1.2.</span> <span class="toc-text">第二部分：微调（SFT）与参数高效微调（PEFT）（实战题）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9Arlhf-%E4%B8%8E%E5%AF%B9%E9%BD%90-%E8%BF%9B%E9%98%B6%E9%A2%98"><span class="toc-number">1.3.</span> <span class="toc-text">第三部分：RLHF 与对齐（进阶题）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%EF%BC%9A%E5%B7%A5%E7%A8%8B%E4%B8%8E%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96-%E5%8A%A0%E5%88%86%E9%A2%98"><span class="toc-number">1.4.</span> <span class="toc-text">第四部分：工程与推理优化（加分题）</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/GRPO/" title="GRPO算法"><img src="/imgs/algorithm.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GRPO算法"/></a><div class="content"><a class="title" href="/2026/02/09/GRPO/" title="GRPO算法">GRPO算法</a><time datetime="2026-02-09T07:45:15.419Z" title="Created 2026-02-09 15:45:15">2026-02-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题"><img src="/imgs/interview.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="面试题"/></a><div class="content"><a class="title" href="/2026/02/09/%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题">面试题</a><time datetime="2026-02-09T07:40:12.377Z" title="Created 2026-02-09 15:40:12">2026-02-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/%E7%AE%97%E6%B3%95/" title="一些算法"><img src="/imgs/algorithm.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="一些算法"/></a><div class="content"><a class="title" href="/2026/02/09/%E7%AE%97%E6%B3%95/" title="一些算法">一些算法</a><time datetime="2026-02-09T06:13:21.763Z" title="Created 2026-02-09 14:13:21">2026-02-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/09/ZeRO3/" title="DeepSpeed ZeRO技术"><img src="/imgs/Flash-Attention.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DeepSpeed ZeRO技术"/></a><div class="content"><a class="title" href="/2026/02/09/ZeRO3/" title="DeepSpeed ZeRO技术">DeepSpeed ZeRO技术</a><time datetime="2026-02-09T06:13:21.762Z" title="Created 2026-02-09 14:13:21">2026-02-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/09/%E5%90%84%E7%A7%8DNormalization/" title="Untitled">Untitled</a><time datetime="2026-02-09T06:13:21.762Z" title="Created 2026-02-09 14:13:21">2026-02-09</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Mercik</span></div><div class="footer_custom_text">I wish you to become your own sun, no need to rely on who's light.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: 'uu6tSxmBoCndulFYKGKobx2L-MdYXbMMI',
      appKey: 'jBho9VeFfJwBsfbRDlg0zM6B',
      avatar: '',
      serverURLs: 'https://uu6tsxmb.api.lncldglobal.com',
      emojiMaps: "",
      visitor: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script src="/js/custom.js"></script><script src="/js/mode_change.js"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script defer data-pjax src="/js/cat.js"></script><script type="text/javascript" src="https://unpkg.zhimg.com/jquery@latest/dist/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://duqi666.github.io/categories/大模型/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 大模型LLM (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://duqi666.github.io/categories/强化学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 强化学习 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://duqi666.github.io/categories/多模态/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱‍👓 多模态 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://duqi666.github.io/categories/算法/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 算法 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://duqi666.github.io/categories/大模型优化/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💡 大模型优化 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://duqi666.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--btn-bg)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/ZeRO3/" alt=""><img width="48" height="48" src="/imgs/Flash-Attention.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/ZeRO3/" alt="">DeepSpeed ZeRO技术</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/ZeRO3/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/Flash-Attention/" alt=""><img width="48" height="48" src="/imgs/Flash-Attention.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/Flash-Attention/" alt="">Flash-Attention算法</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/Flash-Attention/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/Reinforcement_Learning_part2/" alt=""><img width="48" height="48" src="/imgs/RL2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/Reinforcement_Learning_part2/" alt="">《深度学习4-强化学习》学习笔记-2</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/Reinforcement_Learning_part2/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/PPO/" alt=""><img width="48" height="48" src="/imgs/Reinforcement_Learning.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/PPO/" alt="">强化学习PPO算法</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/PPO/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/Reinforcement_Learning/" alt=""><img width="48" height="48" src="/imgs/Reinforcement_Learning.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/Reinforcement_Learning/" alt="">《深度学习4-强化学习》学习笔记</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/Reinforcement_Learning/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/算法/" alt=""><img width="48" height="48" src="/imgs/algorithm.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/算法/" alt="">一些算法</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/算法/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/面试题/" alt=""><img width="48" height="48" src="/imgs/interview.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/面试题/" alt="">面试题</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/面试题/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/RLHF/" alt=""><img width="48" height="48" src="/imgs/thumbnail.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/RLHF/" alt="">人类反馈强化学习：RLHF</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/RLHF/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/MQA&amp;GQA/" alt=""><img width="48" height="48" src="/imgs/MQA&amp;GQA.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/MQA&amp;GQA/" alt="">MQA&amp;GQA</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/MQA&amp;GQA/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/MOE/" alt=""><img width="48" height="48" src="/imgs/MOE.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/MOE/" alt="">MOE模型</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/MOE/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/GRPO/" alt=""><img width="48" height="48" src="/imgs/algorithm.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/GRPO/" alt="">GRPO算法</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/GRPO/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/DPO/" alt=""><img width="48" height="48" src="/imgs/algorithm.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/DPO/" alt="">DPO算法</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/DPO/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/CLIP/" alt=""><img width="48" height="48" src="/imgs/clip.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/CLIP/" alt="">多模态模型--CLIP</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/CLIP/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2026/02/09/Diagrammatize_GPT/" alt=""><img width="48" height="48" src="/imgs/GPT2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-02-09</span><a class="blog-slider__title" href="2026/02/09/Diagrammatize_GPT/" alt="">《GPT图解》学习笔记</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2026/02/09/Diagrammatize_GPT/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('post-class');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '0.5s');
    arr[i].setAttribute('data-wow-delay', '0s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('archive-class');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('page-class');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>